Metadata-Version: 2.4
Name: MIR
Version: 0.0.1
Summary: Machine Intelligence Resource URI Schema
Project-URL: Homepage, https://github.com/darkshapes/MIR
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: tqdm
Requires-Dist: nnll[nnll-01,nnll-04,nnll-30,nnll-44,nnll-60]@ git+https://github.com/darkshapes/nnll@x.dev-refactor
Requires-Dist: pydantic>=2.10.6
Requires-Dist: huggingface-hub[hf-transfer,hf_xet]>=0.30.2
Provides-Extra: dev
Requires-Dist: pytest>=8.3.5; extra == "dev"
Requires-Dist: pytest-asyncio>=0.26.0; extra == "dev"
Requires-Dist: ruff>=0.11.6; extra == "dev"
Dynamic: license-file

---
language:
- en
library_name: mir
license_name: LGPL-3.0-only
---

# MIR (Machine Intelligence Resource)<br><br>A naming schema for AIGC/ML work.

The MIR classification format seeks to standardize and complete a hyperlinked network of model information, improving accessibility and reproducibility across the AI community.<br>
The work is inspired by:
- [AIR-URN](https://github.com/civitai/civitai/wiki/AIR-%E2%80%90-Uniform-Resource-Names-for-AI) project by [CivitAI](https://civitai.com/)
- [Spandrel](https://github.com/chaiNNer-org/spandrel/blob/main/libs/spandrel/spandrel/__helpers/registry.py) library's super-resolution registry



> [!NOTE]
> ## Example:
> ## mir : model . transformer . clip-l : stable-diffusion-xl
>
>
> ```
> mir : model .    lora      .    hyper    :   flux-1
>   ↑      ↑         ↑               ↑            ↑
>  [URI]:[Domain].[Architecture].[Series]:[Compatibility]
> ```


## Purpose:

The purpose of MIR is to create a universal, independent human and machine-readable format for reference metadata related to artificial intelligence research models, algorithms, tensor shapes, libraries, function expressions, and any other property required to operate the models. As this information rapidly accumulates, the intent of MIR is to function as both an archive and a hyperlink to the essential parameters for models and their operation conditions. There is particular emphesis on diffusion models, LLM models, and LoRA, but any kind of model can be described and included in the work.

## Definitions:

Like other URI schema, the order of the identifiers roughly indicates their specificity from left (broad) to right (narrow)
Current entries are listed in the [template](https://github.com/darkshapes/MIR/blob/efd2d82dca61beccf432cb16373cdd6788e658db/mir/mir_template.json)

### Domains

- `dev`: Varying local neural network layers, in-training, pre-release, items under evaluation, likely in unexpected formats. Files.<br>
- `model`: Static local neural network layers. Publicly released machine learning models with an identifier in the database. Files.<br>
- `operations`: Varying global neural network attributes, algorithms, optimizations and procedures on models. Equations or library functions.<br>
- `info`:  Static global neural network attributes, parameters with an identifier in the database. Metadata.<br>

### Architecture
Broad and general terms for system architectures. Example:

- `dit`: Diffusion transformer, typically Vision Synthesis
- `unet`: Unet diffusion structure
- `art` : Autoregressive transformer, typically LLMs
- `lora`: Low-Rank Adapter (may work with dit or transformer)
- `vae`: Variational Autoencoder
...
- etc

### Series
Foundational network and technique types.

### Compatibility
Implementation details based on version-breaking changes, configuration inconsistencies, or other conflicting indicators that have practical application.


### Goals
- Standard identification scheme for **ALL** fields of ML-related development
- Simplification of code for model-related logistics
- Rapid retrieval of resources and metadata
- Efficient and reliable compatibility checks
- Organized hyperparameter management

> <details> <summary>Why not use `diffusion`/`sgm`, `ldm`/`text`/hf.co folder-structure/brand or trade name/preprint paper/development house/algorithm</summary>
>
> - The format here isnt finalized, but overlapping resource definitions or complicated categories that are difficult to narrow have been pruned
> - Likewise, definitions that are too specific have also been trimmed
> - HF.CO become inconsistent across folders/files and often the metadata enforcement of many important developments is neglected
> - Development credit often shared, [Paper heredity tree](https://www.connectedpapers.com/search?q=generative%20diffusion), super complicated
> - Algorithms (esp application) are less common knowledge, vague, ~~and I'm too smooth-brain.~~
> - Overall an attempt at impartiality and neutrality with regards to brand/territory origins
> </details>

> <details><summary>Why `unet`, `dit`, `lora` over alternatives</summary>
>
> - UNET/DiT/Transformer are shared enough to be genre-ish but not too narrowly specific
> - Very similar technical process on this level
> - Functional and efficient for random lookups
> - Short to type
> </details>

> <details><summary>Roadmap</summary>
>
> - Decide on `@` or `:` delimiters (like @8cfg for an indistinguishable 8 step lora that requires cfg)
> - crucial spec element, or an optional, MIR app-determined feature?
> - Proof of concept generative model registry
> - Ensure compatability/integration/cross-pollenation with [OECD AI Classifications](https://oecd.ai/en/classification)
> - Ensure compatability/integration/cross-pollenation with [NIST AI 200-1 NIST Trustworthy and Responsible AI](https://www.nist.gov/publications/ai-use-taxonomy-human-centered-approach)
> </details>

![image/png](https://cdn-uploads.huggingface.co/production/uploads/65ff1816871b36bf84fc3c37/NWZideVk_pp_4OzQDl96w.png)

massive thank you to [@silveroxides](https://huggingface.co/silveroxides) for phenomenal work collecting pristine state dicts and related information

#
